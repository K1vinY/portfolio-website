<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assistive Listening Device & Clinical Trials - Kevin Yu Portfolio</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <h2>Kevin Yu</h2>
            </div>
            <ul class="nav-menu">
                <li class="nav-item"><a href="index.html#home" class="nav-link">Home</a></li>
                <li class="nav-item"><a href="index.html#about" class="nav-link">About Me</a></li>
                <li class="nav-item"><a href="index.html#portfolio" class="nav-link">Projects</a></li>
                <li class="nav-item"><a href="index.html#experience" class="nav-link">Experience</a></li>
                <li class="nav-item"><a href="index.html#publications" class="nav-link">Publications</a></li>
                <li class="nav-item"><a href="index.html#resume" class="nav-link">Resume</a></li>
                <li class="nav-item"><a href="index.html#contact" class="nav-link">Contact</a></li>
            </ul>
            <div class="hamburger">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <section class="project-detail">
        <div class="container">
            <div class="back-button">
                <a href="index.html#portfolio" class="back-link"><i class="fas fa-arrow-left"></i> Back to Projects</a>
            </div>

            <div class="project-header">
                <h1 class="project-title">Development of Assistive Listening Device and Clinical Trials</h1>
                <div class="project-meta">
                    <div class="meta-item"><i class="fas fa-calendar-alt"></i><span>July 2022 - Aug 2023</span></div>
                    <div class="meta-item"><i class="fas fa-map-marker-alt"></i><span>National Cheng Kung University, National Cheng Kung University Hospital</span></div>
                    <div class="meta-item"><i class="fas fa-tag"></i><span>Biomedical</span></div>
                </div>
            </div>

            <div class="project-summary">
                <h2>Abstract</h2>
                <p>According to related researches, the reasons to users unwilling to wear assistive listening devices (ALDs) is the risk of unable to determine the position of sound. In addition, the ALD proposed in this study can perform 360° scan and determine the position. However, it cannot determine the vertical position of the target, resulting in fluctuating volume. Therefore, this study proposes a new sensors fusion method for space perception by the space perception module on ALD that combines computer vision (CV) technology, dual-layer differential microphone arrays (d-DMA) algorithm, time difference of arrival (TDOA), and mixing algorithm. It is primarily designed for patients with mild-to-moderate hearing loss, and the prototype has been developed. This device enhances the target speech (TS) and adjusts the volume output of dual-channels to achieve an immersive auditory experience through the mixing algorithm. This helps mitigate the risk by the inability to determine the position of sound. Furthermore, this study addresses the issue of fluctuating volume by the d-DMA. Based on the results, the proposed device achieves an image accuracy rate over 94% at a normal conversation distance (<160 cm), with 30° of sound reception range. In addition, the stability of volume output is improved by 60% compared with commercial ALD. Clinical results demonstrate that the device enhances the speech recognition threshold (SRT) by 5.5 dB in quiet environments and 5.8 dB in noisy environments. Finally, participants’ satisfaction with the device in both the environments indicates the potential of this device for future commercialization.</p>
            </div>

            <div class="project-content">
                <div class="content-section">
                    <h2>The What</h2>
                    <div class="content-text">
                        <p>Hearing loss affects over 1.5 billion people worldwide, yet 75% of those with hearing impairments are reluctant to use ALDs. A major issue with existing ALDs is their inability to accurately determine the position of a sound source, particularly its elevation, leading to fluctuating volume and difficulty in spatial awareness. This study aims to develop an ALD with improved space perception and immersive auditory experience to enhance speech recognition and user satisfaction.</p>
                    </div>
                </div>

                <div class="content-section">
                    <h2>The How</h2>
                    <div class="content-text">
                        <p>We designed a wearable assistive listening device integrating a space perception module that combines CV, d-DMA, TDOA, and a Mixing Algorithm. This system detects and tracks sound sources, balances volume output, and enhances speech perception by adjusting dual-channel audio. A prototype was developed and tested in various environments to evaluate its performance in improving sound localization and speech recognition.</p>
                    </div>
                </div>

                <div class="content-section">
                    <h2>Results & Impact</h2>
                    <div class="results-content">
                        <div class="results-text">
                            <p>Experimental results demonstrated that the device achieved an image recognition accuracy of over 94% within normal conversation distances and a sound reception range of 30 degrees. The d-DMA algorithm improved volume stability by 60%, while clinical trials showed a 5.5 dB improvement in speech recognition in quiet environments and 5.8 dB in noisy environments. User satisfaction exceeded 3 points on a Likert scale, indicating positive reception and potential for commercialization. This innovation enhances ALD functionality, improving both hearing and spatial awareness for individuals with mild to moderate hearing loss.</p>
                        </div>
                        <div class="hearing-results-images">
                            <div class="image-pair">
                                <img src="images/hearing-result1.png" alt="Hearing Device Result 1">
                                <img src="images/hearing-result2.png" alt="Hearing Device Result 2">
                            </div>
                            <div class="single-image">
                                <img src="images/hearing-result3.png" alt="Hearing Device Result 3">
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="project-technologies">
                <h3>Technologies Used</h3>
                <div class="tech-tags">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">Andriod Studio</span>
                    <span class="tech-tag">Circuit Design</span>
                    <span class="tech-tag">Prototyping</span>
                    <span class="tech-tag">Clinical Trials</span>
                </div>
            </div>

            <div class="project-links">
                <h3>Related Links</h3>
                <div class="link-buttons">
                    <a class="link-button" href="https://ieeexplore.ieee.org/document/10345498?source=authoralert" target="_blank" rel="noopener noreferrer">Research Paper</a>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Kevin Yu. All Rights Reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>


